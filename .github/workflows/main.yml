name: Text to Video Generator

on:
  workflow_dispatch:
    inputs:
      text_prompt:
        description: 'Text prompt for video generation'
        required: true
        type: string
        default: 'A beautiful sunset over mountains with flying birds'
      duration:
        description: 'Video duration in seconds'
        required: false
        type: number
        default: 10
      resolution:
        description: 'Video resolution'
        required: false
        type: choice
        options:
        - 480x360
        - 640x480
        - 1280x720
        - 1920x1080
        default: '1280x720'
      style:
        description: 'Video style'
        required: false
        type: choice
        options:
        - slideshow
        - animated_text
        - ken_burns
        default: 'animated_text'

jobs:
  generate-video:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      
    - name: Setup Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg
        sudo apt-get install -y libsm6 libxext6
        sudo apt-get install -y fonts-dejavu-core fonts-liberation
        sudo apt-get install -y python3-tk
      
    - name: Install Python packages
      run: |
        python -m pip install --upgrade pip
        pip install opencv-python-headless==4.8.1.78
        pip install Pillow==10.0.1
        pip install numpy==1.24.3
        pip install requests==2.31.0
        pip install imageio==2.31.1
        pip install imageio-ffmpeg==0.4.9
        
    - name: Create video generation script
      run: |
        cat > generate_video.py << 'EOF'
        #!/usr/bin/env python3
        import argparse
        import os
        import cv2
        import numpy as np
        from PIL import Image, ImageDraw, ImageFont
        import textwrap
        import random
        
        class VideoGenerator:
            def __init__(self, width=1280, height=720):
                self.width = width
                self.height = height
                self.fps = 24
                
            def create_animated_text_video(self, text_prompt, duration=10):
                """Create animated text video with effects"""
                total_frames = int(duration * self.fps)
                frames = []
                
                # Split text into lines for better display
                words = text_prompt.split()
                lines = []
                current_line = ""
                
                for word in words:
                    if len(current_line + " " + word) <= 30:
                        current_line += " " + word
                    else:
                        lines.append(current_line.strip())
                        current_line = word
                if current_line:
                    lines.append(current_line.strip())
                
                # If text is too short, use the whole text
                if not lines:
                    lines = [text_prompt]
                
                for i in range(total_frames):
                    # Create gradient background that changes over time
                    progress = i / total_frames
                    r = int(50 + 50 * np.sin(progress * 2 * np.pi))
                    g = int(100 + 50 * np.sin(progress * 2 * np.pi + 2))
                    b = int(150 + 50 * np.sin(progress * 2 * np.pi + 4))
                    
                    img = Image.new('RGB', (self.width, self.height), color=(r, g, b))
                    draw = ImageDraw.Draw(img)
                    
                    # Add some visual elements
                    self._add_visual_elements(draw, i)
                    
                    # Use default font (no external font dependencies)
                    try:
                        font_size = 40
                        font = ImageFont.load_default()
                        # Scale default font
                        from PIL import ImageFont
                        try:
                            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
                        except:
                            font = ImageFont.load_default()
                    except:
                        font = ImageFont.load_default()
                    
                    # Calculate text position with animation
                    y_offset = int(50 * np.sin(i * 0.1))
                    
                    # Draw each line of text
                    for j, line in enumerate(lines):
                        try:
                            # Try to get text bounding box
                            bbox = draw.textbbox((0, 0), line, font=font)
                            text_width = bbox[2] - bbox[0]
                        except:
                            # Fallback: estimate width
                            text_width = len(line) * font_size // 2
                        
                        x = (self.width - text_width) // 2
                        y = (self.height - len(lines) * 50) // 2 + j * 50 + y_offset
                        
                        # Text shadow
                        shadow_color = (0, 0, 0)
                        draw.text((x+3, y+3), line, font=font, fill=shadow_color)
                        # Main text with color gradient
                        text_color = (255, 255 - j*30, 100 + j*20)
                        draw.text((x, y), line, font=font, fill=text_color)
                    
                    # Convert to OpenCV format
                    frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                    frames.append(frame)
                
                return frames
            
            def create_slideshow_video(self, text_prompt, duration=10):
                """Create slideshow-style video"""
                total_frames = int(duration * self.fps)
                frames = []
                words = text_prompt.split()
                
                if not words:
                    words = ["Text", "To", "Video"]
                
                # Create slides with different backgrounds
                slides_needed = min(5, len(words))
                slide_duration = total_frames // slides_needed if slides_needed > 0 else total_frames
                
                for i in range(total_frames):
                    slide_num = i // slide_duration if slide_duration > 0 else 0
                    if slide_num >= len(words):
                        slide_num = len(words) - 1
                    
                    # Different background for each slide
                    colors = [
                        (70, 130, 180),   # Steel Blue
                        (220, 20, 60),    # Crimson
                        (34, 139, 34),    # Forest Green
                        (255, 140, 0),    # Dark Orange
                        (148, 0, 211)     # Dark Violet
                    ]
                    
                    bg_color = colors[slide_num % len(colors)]
                    img = Image.new('RGB', (self.width, self.height), color=bg_color)
                    draw = ImageDraw.Draw(img)
                    
                    # Add decorative elements
                    self._add_slide_elements(draw, i, slide_num)
                    
                    try:
                        font_size = 60
                        font = ImageFont.load_default()
                        try:
                            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
                        except:
                            font = ImageFont.load_default()
                    except:
                        font = ImageFont.load_default()
                    
                    word = words[slide_num] if slide_num < len(words) else words[-1]
                    
                    try:
                        bbox = draw.textbbox((0, 0), word, font=font)
                        text_width = bbox[2] - bbox[0]
                    except:
                        text_width = len(word) * 30
                    
                    x = (self.width - text_width) // 2
                    y = self.height // 2 - 30
                    
                    draw.text((x, y), word, font=font, fill=(255, 255, 255))
                    
                    frame = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
                    frames.append(frame)
                
                return frames
            
            def create_ken_burns_video(self, text_prompt, duration=10):
                """Create Ken Burns effect video with text overlay"""
                total_frames = int(duration * self.fps)
                frames = []
                
                # Generate background images
                background_images = self._generate_background_images()
                
                for i in range(total_frames):
                    # Select background image with Ken Burns effect
                    bg_idx = (i // (total_frames // len(background_images))) % len(background_images)
                    bg_img = background_images[bg_idx]
                    
                    # Apply zoom and pan (Ken Burns effect)
                    zoom = 1.0 + 0.2 * (i / total_frames)
                    offset_x = int((bg_img.width - self.width) * (i / total_frames))
                    offset_y = int((bg_img.height - self.height) * 0.3 * np.sin(i * 0.05))
                    
                    # Crop and resize
                    left = max(0, offset_x)
                    upper = max(0, offset_y)
                    right = min(left + int(self.width / zoom), bg_img.width)
                    lower = min(upper + int(self.height / zoom), bg_img.height)
                    
                    if right <= left or lower <= upper:
                        # Fallback if crop coordinates are invalid
                        cropped = bg_img.resize((self.width, self.height), Image.LANCZOS)
                    else:
                        cropped = bg_img.crop((left, upper, right, lower))
                        cropped = cropped.resize((self.width, self.height), Image.LANCZOS)
                    
                    draw = ImageDraw.Draw(cropped)
                    
                    try:
                        font_size = 48
                        font = ImageFont.load_default()
                        try:
                            font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", font_size)
                        except:
                            font = ImageFont.load_default()
                    except:
                        font = ImageFont.load_default()
                    
                    # Wrap text
                    wrapped_text = textwrap.fill(text_prompt, width=30)
                    lines = wrapped_text.split('\n')
                    
                    # Draw text with background for readability
                    text_bg_height = len(lines) * 60 + 20
                    text_bg_y = (self.height - text_bg_height) // 2
                    
                    # Semi-transparent background for text
                    text_bg = Image.new('RGBA', (self.width, text_bg_height), (0, 0, 0, 150))
                    cropped_rgba = cropped.convert('RGBA')
                    cropped_rgba.paste(text_bg, (0, text_bg_y), text_bg)
                    final_img = cropped_rgba.convert('RGB')
                    draw = ImageDraw.Draw(final_img)
                    
                    # Draw text
                    for j, line in enumerate(lines):
                        try:
                            bbox = draw.textbbox((0, 0), line, font=font)
                            text_width = bbox[2] - bbox[0]
                        except:
                            text_width = len(line) * 25
                        
                        x = (self.width - text_width) // 2
                        y = text_bg_y + 10 + j * 60
                        
                        # Text shadow
                        draw.text((x+2, y+2), line, font=font, fill=(0, 0, 0))
                        # Main text
                        draw.text((x, y), line, font=font, fill=(255, 255, 255))
                    
                    frame = cv2.cvtColor(np.array(final_img), cv2.COLOR_RGB2BGR)
                    frames.append(frame)
                
                return frames
            
            def _add_visual_elements(self, draw, frame_num):
                """Add visual elements to the frame"""
                # Add floating shapes
                for i in range(5):
                    x = int(self.width * 0.2 * i + 50 * np.sin(frame_num * 0.1 + i))
                    y = int(self.height * 0.8 + 30 * np.cos(frame_num * 0.05 + i))
                    size = 20 + int(10 * np.sin(frame_num * 0.1 + i))
                    
                    color = (
                        int(255 * abs(np.sin(frame_num * 0.02 + i))),
                        int(255 * abs(np.sin(frame_num * 0.02 + i + 2))),
                        int(255 * abs(np.sin(frame_num * 0.02 + i + 4)))
                    )
                    
                    draw.ellipse([x, y, x+size, y+size], fill=color)
            
            def _add_slide_elements(self, draw, frame_num, slide_num):
                """Add decorative elements to slides"""
                # Add border
                border_width = 10
                draw.rectangle(
                    [border_width, border_width, self.width-border_width, self.height-border_width],
                    outline=(255, 255, 255),
                    width=5
                )
                
                # Add animated elements
                for i in range(3):
                    angle = frame_num * 0.1 + i
                    x = int(self.width * 0.1 + 50 * np.sin(angle))
                    y = int(self.height * 0.1 + 50 * np.cos(angle))
                    size = 30
                    
                    draw.rectangle([x, y, x+size, y+size], fill=(255, 255, 255))
            
            def _generate_background_images(self):
                """Generate background images"""
                images = []
                
                # Create gradient backgrounds
                colors = [
                    (65, 105, 225),  # Royal Blue
                    (220, 20, 60),   # Crimson
                    (50, 205, 50),   # Lime Green
                    (255, 165, 0),   # Orange
                    (138, 43, 226)   # Blue Violet
                ]
                
                for color in colors:
                    # Create larger image for Ken Burns effect
                    img = Image.new('RGB', (self.width * 2, self.height * 2), color=color)
                    
                    # Add some texture
                    draw = ImageDraw.Draw(img)
                    for i in range(30):  # Reduced for performance
                        x = random.randint(0, self.width * 2)
                        y = random.randint(0, self.height * 2)
                        radius = random.randint(20, 100)
                        shade = random.randint(-40, 40)
                        circle_color = (
                            max(0, min(255, color[0] + shade)),
                            max(0, min(255, color[1] + shade)),
                            max(0, min(255, color[2] + shade))
                        )
                        draw.ellipse([x, y, x+radius, y+radius], fill=circle_color)
                    
                    images.append(img)
                
                return images
        
        def save_video(frames, output_path, fps=24, width=1280, height=720):
            """Save frames as video using OpenCV"""
            if not frames:
                raise ValueError("No frames to save")
                
            # Create video writer
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
            
            for frame in frames:
                out.write(frame)
            
            out.release()
            print(f"✅ Video saved: {output_path}")
        
        def main():
            parser = argparse.ArgumentParser(description='Generate video from text')
            parser.add_argument('--prompt', type=str, required=True)
            parser.add_argument('--duration', type=int, default=10)
            parser.add_argument('--resolution', type=str, default='1280x720')
            parser.add_argument('--style', type=str, default='animated_text')
            
            args = parser.parse_args()
            
            # Parse resolution
            try:
                width, height = map(int, args.resolution.split('x'))
                if width <= 0 or height <= 0:
                    raise ValueError("Invalid resolution")
            except:
                width, height = 1280, 720
                print("⚠️  Invalid resolution, using default 1280x720")
            
            # Validate duration
            duration = max(1, min(60, args.duration))  # Limit to 1-60 seconds
            
            # Create output directory
            os.makedirs('output', exist_ok=True)
            
            # Initialize generator
            generator = VideoGenerator(width, height)
            
            print(f"🎬 Generating {duration}s video: '{args.prompt}'")
            print(f"🎨 Style: {args.style}, 📐 Resolution: {width}x{height}")
            
            # Generate frames based on style
            try:
                if args.style == 'slideshow':
                    print("🖼️  Creating slideshow video...")
                    frames = generator.create_slideshow_video(args.prompt, duration)
                elif args.style == 'ken_burns':
                    print("🎞️  Creating Ken Burns effect video...")
                    frames = generator.create_ken_burns_video(args.prompt, duration)
                else:  # animated_text
                    print("✨ Creating animated text video...")
                    frames = generator.create_animated_text_video(args.prompt, duration)
                
                # Save video
                output_path = 'output/generated_video.mp4'
                save_video(frames, output_path, generator.fps, width, height)
                
                print("✅ Video generation completed successfully!")
                return output_path
                
            except Exception as e:
                print(f"❌ Error generating video: {str(e)}")
                import traceback
                traceback.print_exc()
                return None
        
        if __name__ == "__main__":
            main()
        EOF
        
    - name: Generate video from text
      id: generate
      run: |
        echo "🚀 Starting video generation..."
        python generate_video.py \
          --prompt "${{ github.event.inputs.text_prompt }}" \
          --duration ${{ github.event.inputs.duration }} \
          --resolution ${{ github.event.inputs.resolution }} \
          --style ${{ github.event.inputs.style }}
        
    - name: Check if video was generated
      run: |
        if [ -f "output/generated_video.mp4" ]; then
          echo "✅ Video generated successfully!"
          echo "📊 File size: $(du -h output/generated_video.mp4 | cut -f1)"
        else
          echo "❌ Video generation failed"
          exit 1
        fi
        
    - name: Optimize video with FFmpeg
      run: |
        echo "⚡ Optimizing video..."
        ffmpeg -i output/generated_video.mp4 \
          -vcodec libx264 \
          -crf 23 \
          -preset fast \
          -movflags +faststart \
          -y output/final_video.mp4 2>/dev/null || echo "FFmpeg optimization completed"
        
        if [ -f "output/final_video.mp4" ]; then
          echo "✅ Video optimized"
          echo "📊 Original size: $(du -h output/generated_video.mp4 | cut -f1)"
          echo "📊 Optimized size: $(du -h output/final_video.mp4 | cut -f1)"
        else
          # If optimization fails, use original
          cp output/generated_video.mp4 output/final_video.mp4
          echo "⚠️ Using original video (optimization skipped)"
        fi
        
    - name: Create video thumbnail
      run: |
        echo "🖼️ Creating thumbnail..."
        ffmpeg -i output/final_video.mp4 \
          -ss 00:00:01 \
          -vframes 1 \
          -q:v 2 \
          -y output/thumbnail.jpg 2>/dev/null || echo "Thumbnail creation completed"
        
    - name: Generate video info file
      run: |
        echo "# 🎥 Text-to-Video Generation Report" > output/README.md
        echo "" >> output/README.md
        echo "## Prompt" >> output/README.md
        echo "\`\`\`" >> output/README.md
        echo "${{ github.event.inputs.text_prompt }}" >> output/README.md
        echo "\`\`\`" >> output/README.md
        echo "" >> output/README.md
        echo "## Settings" >> output/README.md
        echo "- **Duration:** ${{ github.event.inputs.duration }} seconds" >> output/README.md
        echo "- **Resolution:** ${{ github.event.inputs.resolution }}" >> output/README.md
        echo "- **Style:** ${{ github.event.inputs.style }}" >> output/README.md
        echo "- **Generated:** $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> output/README.md
        echo "" >> output/README.md
        echo "## Files" >> output/README.md
        echo "1. \`final_video.mp4\` - Main video file" >> output/README.md
        echo "2. \`thumbnail.jpg\` - Video thumbnail" >> output/README.md
        echo "" >> output/README.md
        echo "---" >> output/README.md
        echo "*Generated automatically using GitHub Actions*" >> output/README.md
        
    - name: Upload video artifacts
      uses: actions/upload-artifact@v4
      with:
        name: text-to-video-${{ github.run_number }}
        path: |
          output/final_video.mp4
          output/thumbnail.jpg
          output/README.md
        retention-days: 30
        
    - name: Show completion message
      if: success()
      run: |
        echo ""
        echo "🎉 TEXT-TO-VIDEO GENERATION COMPLETED!"
        echo "======================================"
        echo ""
        echo "📝 Prompt: ${{ github.event.inputs.text_prompt }}"
        echo "⏱️  Duration: ${{ github.event.inputs.duration }}s"
        echo "📐 Resolution: ${{ github.event.inputs.resolution }}"
        echo "🎨 Style: ${{ github.event.inputs.style }}"
        echo ""
        echo "📁 Download the generated video from the"
        echo "   'Artifacts' section above ↑"
        echo ""
        echo "🔄 To generate another video, run this workflow again!"
        
    - name: Cleanup temporary files
      if: always()
      run: |
        rm -f output/generated_video.mp4
        echo "🧹 Cleanup completed"
